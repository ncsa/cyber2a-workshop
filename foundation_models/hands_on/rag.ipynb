{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG Hands-on tutorial\n",
    "\n",
    "1. Prepare data \n",
    "2. Create a vector store\n",
    "3. Search the vector store and retrieve relevant documents\n",
    "4. Call LLM with the user query and the retrieved documents\n",
    "4. Return the LLM response to the user\n",
    "\n",
    "Will be using [Langchain framework](https://www.langchain.com/)\n",
    "\n",
    "Suggested code references:\n",
    "- Langchain RAG from scratch [link](https://github.com/langchain-ai/rag-from-scratch/tree/main)\n",
    "- Langchain RAG quickstart [link](https://python.langchain.com/v0.1/docs/use_cases/question_answering/quickstart/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic imports\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "import sys\n",
    "import mlflow\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# create and configure logger\n",
    "logging.basicConfig(level=logging.INFO, datefmt='%Y-%m-%dT%H:%M:%S',\n",
    "                    format='%(asctime)-15s.%(msecs)03dZ %(levelname)-7s : %(name)s - %(message)s',\n",
    "                    handlers=[logging.StreamHandler(sys.stdout)]\n",
    "                    )\n",
    "# create log object with current module name\n",
    "log = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare data\n",
    "- Load data from different sources\n",
    "- Will be using NCSA Delta documentation as an example - in delta_docs folder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Data Loaders\n",
    "- Langchain provides different data loaders for different file types\n",
    "- Data loaded in Langchain Document class format [document class](https://api.python.langchain.com/en/latest/documents/langchain_core.documents.base.Document.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loaders\n",
    "from langchain_community.document_loaders import CSVLoader, DataFrameLoader, PyPDFLoader, Docx2txtLoader, UnstructuredRSTLoader, DirectoryLoader\n",
    "\n",
    "\n",
    "class DataLoaders:\n",
    "    \"\"\"\n",
    "    various data loaders\n",
    "    \"\"\"\n",
    "    def __init__(self, data_dir_path):\n",
    "        self.data_dir_path = data_dir_path\n",
    "    \n",
    "    def csv_loader(self):\n",
    "        csv_loader_kwargs = {\n",
    "                            \"csv_args\":{\n",
    "                                \"delimiter\": \",\",\n",
    "                                \"quotechar\": '\"',\n",
    "                                },\n",
    "                            }\n",
    "        dir_csv_loader = DirectoryLoader(self.data_dir_path, glob=\"**/*.csv\", use_multithreading=True,\n",
    "                                    loader_cls=CSVLoader, \n",
    "                                    loader_kwargs=csv_loader_kwargs,\n",
    "                                    )\n",
    "        return dir_csv_loader\n",
    "    \n",
    "    def pdf_loader(self):\n",
    "        dir_pdf_loader = DirectoryLoader(self.data_dir_path, glob=\"**/*.pdf\",\n",
    "                                    loader_cls=PyPDFLoader,\n",
    "                                    )\n",
    "        return dir_pdf_loader\n",
    "    \n",
    "    def word_loader(self):\n",
    "        dir_word_loader = DirectoryLoader(self.data_dir_path, glob=\"**/*.docx\",\n",
    "                                    loader_cls=Docx2txtLoader,\n",
    "                                    )\n",
    "        return dir_word_loader\n",
    "    \n",
    "    def rst_loader(self):\n",
    "        rst_loader_kwargs = {\n",
    "                        \"mode\":\"single\"\n",
    "                        }\n",
    "        dir_rst_loader = DirectoryLoader(self.data_dir_path, glob=\"**/*.rst\",\n",
    "                                    loader_cls=UnstructuredRSTLoader, \n",
    "                                    loader_kwargs=rst_loader_kwargs\n",
    "                                    )\n",
    "        return dir_rst_loader\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-16T16:25:18.606Z INFO    : __main__ - Loading files from directory delta_docs/selected\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "data_dir_path = os.getenv('DATA_DIR_PATH', \"data\")\n",
    "data_loader = DataLoaders(data_dir_path=data_dir_path)\n",
    "log.info(\"Loading files from directory %s\", data_dir_path)\n",
    "dir_csv_loader = data_loader.csv_loader()\n",
    "dir_word_loader = data_loader.word_loader()\n",
    "dir_pdf_loader = data_loader.pdf_loader()\n",
    "dir_rst_loader = data_loader.rst_loader()\n",
    "csv_data = dir_csv_loader.load()\n",
    "word_data = dir_word_loader.load()\n",
    "pdf_data = dir_pdf_loader.load()\n",
    "rst_data = dir_rst_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Running Jobs\n",
      " \n",
      "Accessing the Compute Nodes\n",
      "Delta implements the Slurm batch environment to manage access to the compute nodes. Use the Slurm\n",
      "commands to run batch jobs or for interactive access to compute nodes. See the Slurm quick start guide for\n",
      "an introduction to Slurm. There are multiple ways to access compute nodes on Delta.\n",
      "Batch scripts (sbatch) or Interactive (srun , salloc), which is right for me?\n",
      "\n",
      ":ref:`sbatch` . Use batch scripts for jobs that are debugged, ready to run, and don't require interaction.\n",
      "Sample Slurm batch job scripts are provided in the :ref:`examples` section. For mixed resource\n",
      "heterogeneous jobs see the Slurm job support documentation. Slurm also supports job arrays for easy\n",
      "management of a set of similar jobs, see the Slurm job array documentation for more information.\n",
      "\n",
      ":ref:`srun` . For interactive use of a compute node, srun will run a single command through Slurm on a\n",
      "compute node. srun blocks, it will wait until Slurm has scheduled compute resources, and when it\n",
      "returns, the job is complete.\n",
      "\n",
      ":ref:`salloc` . Also interactive, use salloc when you want to reserve compute resources for a period of\n",
      "time and interact with them using multiple commands. Each command you type after your salloc\n",
      "session begins will run on the login node if it is just a normal command, or on your reserved compute\n",
      "resources if prefixed with srun. Type exit when finished with an salloc allocation if you want to end it\n",
      "before the time expires.\n",
      "Direct SSH access to a compute node in a running job from a dt-loginNN node is enabled once the job has\n",
      "started:\n",
      "$ squeue --job jobid\n",
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "             12345       cpu     bash   gbauer  R       0:17      1 cn001\n",
      "Then in a terminal session:\n",
      "$ ssh cn001\n",
      "cn001.delta.internal.ncsa.edu (172.28.22.64)\n",
      "  OS: RedHat 8.4   HW: HPE   CPU: 128x    RAM: 252 GB\n",
      "  Site: mgmt  Role: compute\n",
      "$\n",
      "See also, :ref:`mon_node`.\n",
      "Scheduler\n",
      "For information, see the Slurm quick start user guide.\n",
      "' metadata={'source': 'delta_docs/selected/running_jobs.pdf', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "for doc in pdf_data:\n",
    "    print(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Format into text and metadata\n",
    "- Convert data to a list of texts and metadata \n",
    "- Metadata can be used for filtering the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get text and metadata from the data\n",
    "def get_text_metadatas(csv_data=None, pdf_data=None, word_data=None, rst_data=None):\n",
    "    \"\"\"\n",
    "    Each document class has page_content and metadata properties\n",
    "    Separate text and metadata content from Document class\n",
    "    Have custom metadata if needed\n",
    "    \"\"\"\n",
    "    csv_texts = [doc.page_content for doc in csv_data]\n",
    "    # custom metadata\n",
    "    csv_metadatas = [{'source': doc.metadata['source'], 'row_page': doc.metadata['row']} for doc in csv_data]   # metadata={'source': 'filename.csv', 'row': 0}\n",
    "    pdf_texts = [doc.page_content for doc in pdf_data]\n",
    "    pdf_metadatas = [{'source': doc.metadata['source'], 'row_page': doc.metadata['page']} for doc in pdf_data]  # metadata={'source': 'data/filename.pdf', 'page': 8}\n",
    "    word_texts = [doc.page_content for doc in word_data]\n",
    "    word_metadatas = [{'source': doc.metadata['source'], 'row_page': ''} for doc in word_data] \n",
    "    rst_texts = [doc.page_content for doc in rst_data]\n",
    "    rst_metadatas = [{'source': doc.metadata['source'], 'row_page': ''} for doc in rst_data]         # metadata={'source': 'docs/images/architecture/index.rst'}\n",
    "\n",
    "    texts = csv_texts + pdf_texts + word_texts + rst_texts\n",
    "    metadatas = csv_metadatas + pdf_metadatas + word_metadatas + rst_metadatas\n",
    "    return texts, metadatas\n",
    "\n",
    "\n",
    "texts , metadatas = get_text_metadatas(csv_data, pdf_data, word_data, rst_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Chunking\n",
    "- Split texts into chunks for embedding\n",
    "- Return a list of document chunks (list of langchain [document class](https://api.python.langchain.com/en/latest/documents/langchain_core.documents.base.Document.html))\n",
    "\n",
    "![Chunk Optimization](images/chunking.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from typing import List\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200,\n",
    "        separators=[\n",
    "            \"\\n\\n\", \"\\n\", \". \", \" \", \"\"\n",
    "        ]  # try to split on paragraphs... fallback to sentences, then chars, ensure we always fit in context window\n",
    "    )\n",
    "\n",
    "docs: List[Document] = text_splitter.create_documents(texts=texts, metadatas=metadatas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs[0])\n",
    "print(\"Number of documents: \", len(docs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Embeddings\n",
    "- We will be using OpenAI embeddings\n",
    "- text-embedding-ada-002 model for embeddings, which has a maximum token limit of 8191 according to OpenAI documentation.\n",
    "- HF Embedding models leaderboard [link](https://huggingface.co/spaces/mteb/leaderboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings \n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Vector Store\n",
    "- We will use [Qdrant](https://qdrant.tech/) vector store for this example\n",
    "- For today we will use local memory as the vector store\n",
    "- Qdrant has a docker image that can be used to create a vector store and hosted remotely\n",
    "Eg: [Qdrant docker container running locally](http://localhost:6333/dashboard)\n",
    "\n",
    "- Blog post on vector stores [link](https://medium.com/google-cloud/vector-databases-are-all-the-rage-872c888fa348)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-16T16:25:51.683Z INFO    : httpx - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-16T16:25:52.699Z INFO    : httpx - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-16T16:25:54.034Z INFO    : httpx - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-16T16:25:54.609Z INFO    : httpx - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "# creating a qdrant vector store in local memory\n",
    "\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "\n",
    "# qdrant collection name\n",
    "collection_name = os.getenv('QDRANT_COLLECTION_NAME', \"data-collection\")\n",
    "\n",
    "# create vector store in local memory\n",
    "vectorstore = Qdrant.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=embeddings,\n",
    "    location=\":memory:\",  # Local mode with in-memory storage only\n",
    "    collection_name=collection_name,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Retrieve relevant documents\n",
    "Create a retriever from the vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retriever to retrieve relevant snippets\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Call LLM\n",
    "\n",
    "### 4.1 Prompting\n",
    "- Use a prompt template [link](https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.prompt.PromptTemplate.html)\n",
    "    - includes input parameters that can be dynamically changed\n",
    "- Use Langchain hub to pull prompts [link](https://smith.langchain.com/hub)\n",
    "    - easy to share and reuse prompts\n",
    "    - can see what are the popular prompts for specific use cases\n",
    "    - Eg: [rag-prompt](https://smith.langchain.com/hub/rlm/rag-prompt)\n",
    "- Use a custom prompt\n",
    "```\n",
    "qa_prompt_template = \"\"\"Use the following pieces of context to answer the question at the end. Please follow the following rules:\n",
    "    1. If the question has some initial findings, use that as context.\n",
    "    2. If you don't know the answer, don't try to make up an answer. Just say **I can't find the final answer but you may want to check the following sourcess** and add the source documents as a list.\n",
    "    3. If you find the answer, write the answer in a concise way and add the list of sources that are **directly** used to derive the answer. Exclude the sources that are irrelevant to the final answer.\n",
    "\n",
    "    {context}\n",
    "\n",
    "    Question: {question}\n",
    "    Helpful Answer:\"\"\"\n",
    "\n",
    "rag_chain_prompt = PromptTemplate.from_template(qa_prompt_template) \n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompting\n",
    "\n",
    "from langchain import hub\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Call LLM\n",
    "- We will use \n",
    "    - OpenAI GPT-4o-mini and \n",
    "    - Ollama llama3 model (hosted on NCSA Radiant SD-GPU)\n",
    "- Each model has its own formats and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# formatting the documents as a string before calling the LLM\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call open ai GPT-4o-mini\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# create a chat openai model\n",
    "llm: ChatOpenAI = ChatOpenAI(\n",
    "            temperature=0,\n",
    "            model=\"gpt-4o-mini\",\n",
    "            max_retries=500,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-12T15:56:28.077Z INFO    : httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='There isn\\'t a single \"capital of the world\" as each country has its own capital city. However, some cities are often referred to as global capitals due to their significant influence in international politics, finance, culture, and trade. Examples include New York City, which is home to the United Nations headquarters, and London, which is a major financial center. Ultimately, the concept of a \"capital of the world\" is subjective and can vary based on context.', response_metadata={'token_usage': {'completion_tokens': 92, 'prompt_tokens': 15, 'total_tokens': 107}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'stop', 'logprobs': None}, id='run-ef7164b4-e87d-4f02-acb9-c56d1d67522d-0', usage_metadata={'input_tokens': 15, 'output_tokens': 92, 'total_tokens': 107})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call GPT4o-mini\n",
    "llm.invoke(\"What is the capital of the world?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 RAG Chain\n",
    "Combining it all together\n",
    "\n",
    "- RunnablePassthrough() is used to pass the user query as is to the chain\n",
    "- format_docs is used to format the documents as a string\n",
    "- prompt is used to call the prompt template\n",
    "- llm is used to call the LLM\n",
    "- StrOutputParser() is used to parse the output from the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rag chain\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "openai_rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-16T16:26:57.872Z INFO    : httpx - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-16T16:26:59.540Z INFO    : httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The goals of the symposium included creating a forum for North Slope leaders and residents to engage with scientists and engineers on permafrost-related issues, increasing dialogue between these groups, and developing adaptive strategies for Arctic infrastructure. It aimed to reduce research fatigue by consolidating outreach efforts from multiple science teams and allowing visiting experts to learn from local knowledge. Overall, the symposium sought to enhance understanding of the interactions between permafrost and the built environment.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call openai rag chain\n",
    "openai_rag_chain.invoke(\"What were the goals of the symposium?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call ollama llama3:latest\n",
    "\n",
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "ollama_api_key = os.getenv('OLLAMA_API_KEY')\n",
    "ollama_headers = {\"Authorization\": f\"Bearer {ollama_api_key}\"}\n",
    "\n",
    "# create a ollama model\n",
    "ollamallm: OllamaLLM = OllamaLLM(\n",
    "    base_url=\"https://sd-gpu.ncsa.illinois.edu/ollama\",\n",
    "    model=\"llama3.2:latest\",\n",
    "    headers=ollama_headers,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There is no single \"capital of the world\". Each country has its own capital city, and the concept of a global capital is not universally defined or recognized.\\n\\nHowever, some cities are often referred to as the \"global hubs\" or \"international capitals\" due to their significance in international relations, trade, finance, culture, and politics. Some examples include:\\n\\n1. New York City (USA) - often considered a global financial hub\\n2. London (UK) - a major center for international business and finance\\n3. Paris (France) - a cultural and artistic hub with significant diplomatic influence\\n4. Beijing (China) - a rising economic power with growing global influence\\n5. Geneva (Switzerland) - known as the \"Capital of International Organizations\" due to its hosting many UN agencies\\n\\nIt\\'s worth noting that these designations are subjective and can vary depending on individual perspectives and criteria.\\n\\nIf you\\'re looking for a more neutral answer, I\\'d say there isn\\'t a single city that is universally recognized as the capital of the world.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call llama3 model\n",
    "ollamallm.invoke(\"What is the capital of the world?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ollama rag chain\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "ollama_rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | ollamallm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call ollama rag chain\n",
    "ollama_rag_chain.invoke(\"Who is the president of USA?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## adding sources to openai rag chain\n",
    "\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "openai_rag_chain_from_docs = (\n",
    "    RunnablePassthrough.assign(context=(lambda x: format_docs(x[\"context\"])))\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "openai_rag_chain_with_source = RunnableParallel(\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    ").assign(answer=openai_rag_chain_from_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-16T16:27:26.939Z INFO    : httpx - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-16T16:27:29.160Z INFO    : httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'context': [Document(metadata={'source': 'delta_docs/selected/2023-PI-Symposium-final-report-web.pdf', 'row_page': 63, '_id': '1efab95bab5447e29e6a96377588c25d', '_collection_name': 'delta-collection'}, page_content='63\\nThe symposium provided...\\n• opportunity to connect with other subject matter \\nexperts for on-site discussions and brainstorming \\non climate resilience issues.\\n• insights into the science and management of in-\\nfrastructure-permafrost interactions, including \\nmethods and solutions practiced in other Arctic \\ncountries.\\n• an opportunity for early career researchers to vis-\\nit remote sites and learn from local experts before \\napplying for research funding.\\nThe symposium emphasized...\\n• the need for adaptation strategies based on sci-\\nentific knowledge and partnerships between com-\\nmunity members, permafrost scientists, engineers, \\nand planners.\\n• the importance of incorporating new scientific \\nand engineering knowledge in planning Arctic \\nprojects.\\n• the importance of translating expert work into \\nactionable items for communities.\\n• the importance of sharing permafrost science and \\nengineering principles with a wider audience. The symposium encouraged...\\n• an inclusive approach to research that acknowl-\\nedges the unique issues in different regions and \\nthe value of traditional knowledge.\\n• community engagement and potential collabora-\\ntion on research, starting with grant writing. \\nMore takeaways\\n• The symposium built community, introduced \\nparticipants to real issues in the region in detail, \\nshared science of great relevance, and aided in \\nbuilding relationships and trust. \\n• The respectful debate from differing perspectives \\nchanged several participants thoughts on the key \\nprocesses driving environmental change and the \\nresulting impacts to infrastructure.\\n• An early career scientist working with communi-\\nties reported feeling more inspired and less over -\\nwhelmed after the symposium, knowing they \\nhave many colleagues they can reach out to.\\n• The participation of key NSB employees fostered \\ndialogue between Borough departments. Broad-\\ncasting the NSB Assembly workshop on public \\nradio extended the reach across the region. THE VALUE OF THE SYMPOSIUM\\nReflections on the value of the symposium were shared at the closing session in Fairbanks and six months after the \\nsymposium in an evaluation survey. See the following pages for more participant feedback and specific outcomes. PROCEEDINGS \\nClosing comments: \\nTakeaways\\n6-month evaluation  \\nsurvey\\nReflections by Epstein,  \\nKilioni, Tracey, Xiao  \\n& others'),\n",
       "  Document(metadata={'source': 'delta_docs/selected/2023-PI-Symposium-final-report-web.pdf', 'row_page': 6, '_id': 'e976ddef99d7496aa26e8d363dee924a', '_collection_name': 'delta-collection'}, page_content='6\\nGOALS OF THE SYMPOSIUM\\n• Create a forum for North Slope leaders and residents to engage with top scientists \\nand engineers on high-priority issues\\n• Allow visiting scientists and engineers to see issues related to permafrost thaw and \\nerosion firsthand and to learn from local experts\\n• Increase dialog between scientists and engineers\\n• Reduce research fatigue by consolidating the community outreach and engagement \\nactivities of multiple science teams working in the same region\\n• Develop better adaptive strategies for improving Arctic infrastructure through better \\nunderstanding of the interactions between permafrost and the built environment \\nPHOTO: STEVEN ROWELL/MCAD, 2023'),\n",
       "  Document(metadata={'source': 'delta_docs/selected/2023-PI-Symposium-final-report-web.pdf', 'row_page': 64, '_id': '0427d7bb07f34ed58dec1bb4334d4c31', '_collection_name': 'delta-collection'}, page_content='64\\nTHE PERMAFROST & INFRASTRUCTURE SYMPOSIUM  provided a rare \\nopportunity for visiting scientists, engineers, planners, and \\npolicymakers to witness some of the challenges of living in \\na rapidly warming Arctic. Many more people wished to at-\\ntend than could be accommodated. The limited size was by \\ndesign—necessary due to travel logistics and desirable for \\nfacilitating dialog and knowledge sharing across disciplines. \\nHowever, keeping the participant list small was among the \\nbiggest planning challenges. Recordings of the proceedings \\nare available but are not a substitute for attending in person. \\nBased on event’s success and the overwhelmingly positive \\nfeedback from participants and our partners in the region, \\nthe organizers recommend planning future symposia along \\nthe same model in other regions of Alaska. Communities on \\nthe Seward Peninsula or the Yukon-Kuskokwim Delta expe-\\nrience the impacts of climate change differently than those \\non the North Slope. Local and Indigenous participation in \\nplanning any future events is critical to keeping the dialog \\nfocused on the needs and priorities of Arctic communities. \\nParticipants shared the following suggestions for planning \\nanother symposium on the North Slope or elsewhere:\\nLocal Involvement\\n• More members of local communities should be involved, \\nmore people with Indigenous knowledge, and more rep-\\nresentatives from the local and state government. \\n• Include a field trip for community members to tour re-\\nsearch sites and learn about research being done in their \\ncommunities.\\n• Include more time for discussions with residents about \\nhow to capture their needs and involve them in research.• A more central location in Utqiaġvik would increase in-\\nteraction. We were quite isolated in our venue.\\n• Involve students.\\nIndustry Involvement\\n• Since the oil industry is a big player on the North Slope, \\nmore industry participation and more focus on issues of \\noilfield abandonment and restoration would be good.\\nMore Breaks, More Time, More Field Trips\\n• The days were long. Include more or longer breaks and \\nextra free time. \\n• Go “on location” with more of the experts.\\n• Include time to report out from separate field days.\\n• Include more time to stop at relevant sites on the Dalton \\nHighway and more time for  discussion at the sites.\\nFocus on Climate Impacts\\n• Include targeted discussion on the carbon footprints of \\ninfrastructure projects.\\nFocus on Outcomes\\n• Provide more direction on the front end of expected out-\\ncomes and push to make more outcomes happen. \\n• Extend the symposium for an additional day to hold a \\npost-symposium workshop with all participants in order \\nto develop an action plan and timeline for implementing \\nthe research.\\n• Plan for more specific outcomes that go beyond the post- \\nsymposium reporting. For example, a book with contri-\\nbutions from participants, specific grant opportunities to \\ncollaborate on, or addressing issues that the NSB, BUECI \\nor TNHA are experiencing that might benefit from feed-\\nback from the participants.FUTURE SYMPOSIA'),\n",
       "  Document(metadata={'source': 'delta_docs/selected/2023-PI-Symposium-final-report-web.pdf', 'row_page': 1, '_id': 'b18d7f91784c4166805f9483fd93656e', '_collection_name': 'delta-collection'}, page_content='LEARNING FROM THE\\nPERMAFROST & INFRASTRUCTURE SYMPOSIUM\\nMerging Science, Engineering, and Community-based Knowledge \\nJULY 28–AUGUST 5, 2023\\nCONFERENCE REPORT')],\n",
       " 'question': 'What were the goals of the symposium?',\n",
       " 'answer': 'The goals of the symposium included creating a forum for North Slope leaders and residents to engage with scientists and engineers on permafrost-related issues, increasing dialogue between these groups, and reducing research fatigue by consolidating outreach efforts. It aimed to enhance understanding of permafrost and infrastructure interactions to develop better adaptive strategies for Arctic conditions. Additionally, the symposium sought to provide firsthand experiences of local challenges to visiting experts and foster community engagement in research.'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call openai rag chain with source\n",
    "# this will return the answer and the sources (context)\n",
    "openai_rag_chain_with_source.invoke(\"What were the goals of the symposium?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_rag_chain_with_source.invoke(\"Why is tundra restoration and rehabilitation important\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_rag_chain_with_source.invoke(\"Who is Brenadette Adams?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
